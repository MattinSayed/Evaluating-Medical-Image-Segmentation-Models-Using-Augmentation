{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee2106e-610c-4b57-b246-831abe4a601b",
   "metadata": {},
   "source": [
    "## Scan Augmentation\n",
    "\n",
    "This script handles the augmentation of CT scans and segmentation masks. As a prerequisite, the user must provide the ground truth CT scan files as well as the corresponding ground truth segmentation masks.\n",
    "\n",
    "Please note that the function find_pairs() AND augment_nifti() NEED to be edited BEFORE RUNNING THIS SCRIPT to adapt the corresponding naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839228a-3e6d-46c3-982e-8d7986c73b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16265290-0058-4da1-ad8d-154302f1bc41",
   "metadata": {},
   "source": [
    "Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf4176-c1bf-4478-a275-c97866e13c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_records = []\n",
    "list_of_ids = []\n",
    "inversion_list =[]\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610cb14a-3529-465a-b0ba-0472c3d0c424",
   "metadata": {},
   "source": [
    "#### pick_files():\n",
    "The following methodopens a series of file dialogs for the user to select directories and returns the selected paths.\n",
    "\n",
    "The function prompts the user to select the following directories:\n",
    "1. The folder containing the CT scan niftis.\n",
    "2. The folder containing the segmentation masks of the CT-scan niftis.\n",
    "3. The output directory where processed files will be saved.\n",
    "4. The directory for storing the logging file, the augmentation metadata .xlsx file and the inversion metadata .pth file.\n",
    "\n",
    "Returns:\n",
    "    tuple: A tuple containing four paths (CT_dir_path, SM_dir_path, output_path, logging_output_path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210f5cf-73ad-4b34-9f69-7baf232a0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_files():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main tkinter window\n",
    "    CT_dir_path = filedialog.askdirectory(title=\"Select the folder with the CT SCAN NIFTIS\") \n",
    "    print(f\"Selected folder: {CT_dir_path}\")\n",
    "    SM_dir_path = filedialog.askdirectory(title=\"Select the folder with the SEGMENTATION MASKS of THE CT-SCAN NIFTIS\")\n",
    "    print(f\"Selected folder: {SM_dir_path}\")\n",
    "    output_path = filedialog.askdirectory(title=\"Select the OUTPUT DIRECTORY\")\n",
    "    print(f\"Selected folder: {output_path}\")\n",
    "    logging_output_path = filedialog.askdirectory(title=\"Select the OUTPUT DIRECTORY for the .LOG, .XLSX and .PTH FILES\")\n",
    "    print(f\"Selected folder: {logging_output_path}\")\n",
    "    return CT_dir_path, SM_dir_path, output_path, logging_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f2e6b-377b-4fb8-8978-2949c99f96ac",
   "metadata": {},
   "source": [
    "#### get_nifti_file_paths():\n",
    "Retrieves the file paths of NIfTI files in the specified directory.\n",
    "\n",
    "This function searches for files with '.nii' or '.nii.gz' extensions\n",
    "in the given directory and returns their full paths.\n",
    "\n",
    "Args:\n",
    "    directory_path (str): The path to the directory containing NIfTI files.\n",
    "\n",
    "Returns:\n",
    "    list of str: A list of full file paths for each NIfTI file found in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ae0da-cec8-42e5-8890-35be362c8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nifti_file_paths(directory_path):\n",
    "    return [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.nii') or f.endswith('.nii.gz')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7128ce-89e3-4714-973b-bc8764a92901",
   "metadata": {},
   "source": [
    "#### adjust_hyperparams_for_lvl2():\n",
    "Adjusts hyperparameters for RandomElasticDeformation (Level 2 transformation) based on the image size and spacing to avoid potential folding during elastic deformation.\n",
    "\n",
    "Args:\n",
    "    image (torchio.Image): A torchio Image instance.\n",
    "    num_control_points (int or tuple or list): The number of control points for the deformation grid.\n",
    "\n",
    "Returns:\n",
    "    list of float: A list of three floats representing the maximum displacement for each dimension (x, y, z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92296b0-37b4-4a01-9d69-8704ca8078da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_hyperparams_for_lvl2(image, num_control_points):\n",
    "    image = image.as_sitk()\n",
    "    img_size = image.GetSize()\n",
    "    img_spacing = image.GetSpacing()\n",
    "    bounds = np.array(img_size) * np.array(img_spacing)\n",
    "    grid_spacing = bounds / (num_control_points - 2)\n",
    "    potential_folding = grid_spacing / 2\n",
    "    max_displacement = [0, 0, 0]\n",
    "    max_displacement[0] = potential_folding[0] / 2\n",
    "    max_displacement[1] = potential_folding[1] / 2\n",
    "    return max_displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6004d9a-d09b-4fc9-92d2-db7d145b30a2",
   "metadata": {},
   "source": [
    "#### augment_nifti():\n",
    "\n",
    "Applies a transformation to a CT and a corresponding SM and saves the transformed files. Details of the transformation are noted in the paper.\n",
    "\n",
    "The transformation to be applied is determined by the 'lvl' parameter.\n",
    "Level 1: RandomAffine with scales=(1), degrees=45 (i.e. only rotation)\n",
    "Level 2: RandomElasticDeformation with num_control_points=(50,50,70) and max_displacement as calculated by adjust_hyperparams_for_lvl2\n",
    "Level 3: Composition of Level 2 and Level 1\n",
    "\n",
    "Args:\n",
    "    CT_path (str): The file path of the CT scan NIfTI file.\n",
    "    SM_path (str): The file path of the corresponding segmentation mask NIfTI file.\n",
    "    output_path (str): The directory where the transformed files will be saved.\n",
    "    lvl (str): The level of transformation to be applied (1, 2, or 3).\n",
    "\n",
    "Returns:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963f811-b93c-4399-8679-25ffd19b6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_nifti(CT_path, SM_path, output_path, lvl):\n",
    "    #!---------------- CHANGE NAME BASED ON GIVEN NAMING CONVENTION OF NIFTI FILES -----------------!#\n",
    "    CT_file_name = os.path.splitext(os.path.basename(CT_path))[0].split('.nii')[0]\n",
    "    SM_file_name = os.path.splitext(os.path.basename(SM_path))[0].split('_combined')[0]\n",
    "        \n",
    "    CT_subject = tio.Subject(\n",
    "        image=tio.ScalarImage(CT_path)\n",
    "    )\n",
    "\n",
    "    SM_subject = tio.Subject(\n",
    "        image=tio.LabelMap(SM_path)\n",
    "    )\n",
    "\n",
    "    transformation = 'None'\n",
    "    if lvl == \"1\":\n",
    "        transformation = tio.RandomAffine(scales=(1), degrees=45)\n",
    "\n",
    "    if lvl == \"2\":\n",
    "        num_control_points = (50,50,70)\n",
    "        max_displacement = adjust_hyperparams_for_lvl2(CT_subject['image'], np.array(num_control_points))\n",
    "        transformation = tio.RandomElasticDeformation(num_control_points=num_control_points, max_displacement=max_displacement, locked_borders=2, image_interpolation='nearest') # TODO: should be bspline\n",
    "\n",
    "    if lvl == \"3\":\n",
    "        num_control_points = (50,50,70)\n",
    "        max_displacement = adjust_hyperparams_for_lvl2(CT_subject['image'], np.array(num_control_points))\n",
    "        transform = tio.Compose([\n",
    "            tio.RandomElasticDeformation(num_control_points=num_control_points, max_displacement=max_displacement, locked_borders=2, image_interpolation='nearest'),\n",
    "            tio.RandomAffine(scales=(1), degrees=45),\n",
    "            ])\n",
    "        transformation = transform\n",
    "    \n",
    "    # Apply the transformation\n",
    "    transformed_CT_subject = transformation(CT_subject)\n",
    "\n",
    "    # Get history\n",
    "    SM_transform = transformed_CT_subject.get_composed_history()\n",
    "\n",
    "    # Apply the transformation as described in the transformation history to the SM subject\n",
    "    transformed_SM_subject = SM_transform(SM_subject)\n",
    "\n",
    "    # Get the inverse transformation\n",
    "    inverse_transform = transformed_SM_subject.get_inverse_transform()\n",
    "\n",
    "    # Save the transformed image \n",
    "    CT_file_output_path = get_unique_file_path(f\"{output_path}/CT_{CT_file_name}_lvl_{lvl}_AUGMENTED.nii.gz\")\n",
    "    SM_file_output_path = get_unique_file_path(f\"{output_path}/SM_{SM_file_name}_lvl_{lvl}_AUGMENTED.nii.gz\")\n",
    "    transformed_CT_subject['image'].save(CT_file_output_path)\n",
    "    transformed_SM_subject['image'].save(SM_file_output_path)\n",
    "\n",
    "    # Save metadata for the transformed image\n",
    "    list_of_ids.append(CT_file_name)\n",
    "    image_records.append({\n",
    "        'Input CT Path': CT_path,\n",
    "        'Input SM Path': SM_path,\n",
    "        'Level': lvl,\n",
    "        'Transformation Applied': SM_transform,\n",
    "        'Output CT Path': CT_file_output_path,\n",
    "        'Output SM Path': SM_file_output_path\n",
    "    })\n",
    "    \n",
    "    # Save the inverse transformation information\n",
    "    inversion_list.append((SM_file_output_path, inverse_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0128a-ac6e-4043-9498-2034dd9ac99d",
   "metadata": {},
   "source": [
    "#### get_unique_file_path():\n",
    "\n",
    "Returns a unique file path if the given file path already exists.\n",
    "\n",
    "If the given file path does not exist, it is returned as is.\n",
    "If the file exists, a counter is added to the file name until a unique file is found.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "    file_path : str\n",
    "        The file path to check\n",
    "\n",
    "Returns:\n",
    "\n",
    "    str\n",
    "        The unique file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106df528-b876-47ba-b0dd-0ed469f27b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_file_path(file_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return file_path\n",
    "\n",
    "    # If the file exists, modify the name to make it unique\n",
    "    base, _ = os.path.splitext(file_path)\n",
    "    counter = 1\n",
    "\n",
    "    # Add a counter to the file name until a unique file is found\n",
    "    while os.path.exists(file_path):\n",
    "        file_path = f\"{base}_({counter}).nii.gz\"\n",
    "        counter += 1\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fefa3-054c-4b5b-a3f1-2710a8ded1c2",
   "metadata": {},
   "source": [
    "#### save_records_to_excel():\n",
    "\n",
    "Saves the provided records to an Excel file at the specified output path.\n",
    "\n",
    "This function converts the given records into a pandas DataFrame and\n",
    "saves it as an Excel file named 'augmentation_records_<timestamp>.xlsx'\n",
    "in the specified output directory.\n",
    "\n",
    "Args:\n",
    "\n",
    "    records (list of dict): The records to be saved, where each record\n",
    "                            is a dictionary with the same keys.\n",
    "    output_excel_path (str): The directory path where the Excel file\n",
    "                             will be saved.\n",
    "\n",
    "Returns:\n",
    "\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f696d-dc60-47ce-b8f9-297f63621e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_records_to_excel(records, output_excel_path):\n",
    "    df = pd.DataFrame(records)\n",
    "    output_excel_path = os.path.join(output_excel_path, f'augmentation_records_{timestamp}.xlsx')\n",
    "    # Save to Excel\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"Records saved to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6babbb9-197f-46b9-b296-8447344b2633",
   "metadata": {},
   "source": [
    "#### find_pairs():\n",
    "Finds matching pairs of paths between two lists based on file_names.\n",
    "\n",
    "Given two lists of paths, this function matches the paths by their file_names (ignoring the directory and file extension).\n",
    "!----- THIS NEEDS TO BE EDITED BASED ON THE GIVEN NAMING CONVENTION OF THE NIFTI FILES. ----------!\n",
    "\n",
    "Args:\n",
    "    CT_paths (list of str): List of paths to CT scan NIfTI files.\n",
    "    SM_paths (list of str): List of paths to segmentation mask NIfTI files.\n",
    "\n",
    "Returns:\n",
    "    list of tuple: A list of tuples, where each tuple contains a pair of\n",
    "                   matched paths. The first element of each tuple is a\n",
    "                   path from CT_paths and the second element is a path\n",
    "                   from SM_paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5d8de-a5a6-4981-8b46-13cf0a70c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pairs(CT_paths, SM_paths):\n",
    "    matched_tuples = []\n",
    "    \n",
    "    # Extract file_names from the paths\n",
    "    #!---------------- CHANGE NAME BASED ON GIVEN NAMING CONVENTION OF NIFTI FILES -----------------!#\n",
    "    CT_paths = {\n",
    "    os.path.splitext(os.path.basename(CT_path))[0].split('.nii')[0]: CT_path \n",
    "    for CT_path in CT_paths\n",
    "    }\n",
    "    SM_paths = {\n",
    "    os.path.splitext(os.path.basename(SM_path))[0].split('_combined')[0]: SM_path \n",
    "    for SM_path in SM_paths\n",
    "    }\n",
    "\n",
    "    # Iterate through the file_names in the first list\n",
    "    for file_name, path in CT_paths.items():\n",
    "        # If the same file_name exists in the second list, create a tuple\n",
    "        for file_name2, path2 in SM_paths.items():\n",
    "            if file_name in file_name2:\n",
    "                matched_tuples.append((path, SM_paths[file_name]))\n",
    "    \n",
    "    return matched_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae206d1e-8c9a-47ac-8cec-0ae7245e2229",
   "metadata": {},
   "source": [
    "### Running the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd55a07-72ab-4f02-bf68-6e6c2a3159e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick files and set logging parameters\n",
    "CT_dir_path, SM_dir_path, output_path, logging_output_path = pick_files()\n",
    "excel_output_path = logging_output_path\n",
    "logging_output_path= str(os.path.join(logging_output_path, f'augment_nifti_error.log'))\n",
    "logging.basicConfig(\n",
    "    filename=logging_output_path,\n",
    "    level=logging.ERROR,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "# Get and match paths\n",
    "CT_paths = get_nifti_file_paths(CT_dir_path)\n",
    "SM_paths = get_nifti_file_paths(SM_dir_path)\n",
    "CT_SM_pair = find_pairs(CT_paths, SM_paths)\n",
    "# For each pair of paths, transform the NIfTI files 10 times, each time choosing randomly between lvl 1, 2 or 3\n",
    "for CT_path, SM_path in tqdm(CT_SM_pair, desc=\"Transforming nifti pairs\", total=len(CT_paths)):\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            lvl_transform = random.choice([1, 2, 3])\n",
    "            augment_nifti(CT_path, SM_path, output_path, str(lvl_transform))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error transforming {CT_path} and {SM_path} for level {lvl_transform} in line {sys.exc_info()[2].tb_lineno}: {e}, continuing with next pair...\")\n",
    "            logging.error(traceback.format_exc())\n",
    "            continue\n",
    "try:\n",
    "    # Save accumulated transformation records to excel\n",
    "    save_records_to_excel(image_records, excel_output_path)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving records to Excel in line {sys.exc_info()[2].tb_lineno}: {e}\")\n",
    "    logging.error(traceback.format_exc())\n",
    "try:\n",
    "    # Save accumulated inversion metadata in a .pth file for further use in the inversion\n",
    "    torch.save(inversion_list, os.path.join(output_path, f'inversion_list_{timestamp}.pth'))\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving inversion list in line {sys.exc_info()[2].tb_lineno}: {e}\")\n",
    "    logging.error(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
